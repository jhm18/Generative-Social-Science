.   Calculating Kullbackâ€“Leibler Divergence
.   Jonathan H. Morgan
.   16 June 2021

.   Function takes two arguments: samp_a and samp_b
.   samp_a and samp_b are the two distributions for which we are calculating the divergence.
.   Returns the kl-divergence of the two distributions as a constant.

.   Note:  Some applications support using Base 2 Log of X LOG2(X) or Base 10 LOG10(2) rather than the natural log.
.          I am doing the most basic implementation here using LOG.
.          Also, this is a  forward KL Divergence score, the difference between P(x) and Q(x) is weighted by P(x).
.          This weighing is implemented through the if condition. 
.          If  P(x) > 0, then the log(P(x)/Q(x)) term will contribute to the overall KL Divergence.
.          This implementation is "zero avoiding", namely there is no cases of P(x) > 0 that are not covered by Q(x).
.          This is desirable when you want to assess the differences between the distributions, but poor when trying to minimize the divergence between them because
.          in covering all the cases there will be cases of P(x) that are wrongly covered by Q(x).
.          See https://wiseodd.github.io/techblog/2016/12/21/forward-reverse-kl/ for more details.
.          If the goal is to minimize the divergence, then reverse KL Divergence is beter; this acheived by changing the if condition to weight by Q(x).

.          To Run this Macro with Arguments:  CALL /Users/jonathan.h.morgan/Dataplot_Resources/Dataplot_Utilities/kl_divergence.DP samp_a=x samp_b=x_1
.          I have commented out the arguments, and use NAME in the call script because I often call this function within a loop.

COMMENT Creating Test Samples
.    LET sample_a = DATA 0.02 0.03 0.05 0.14 0.16 0.15 0.12 0.08 0.1 0.08 0.07
.    LET sample_n = SIZE sample_a
.    LET IND = RANDOM PERMUTATION FOR I = 1 1 sample_n
.    LET sample_b = BOOTSTRAP SAMPLE sample_a IND
.    DELETE IND
  
COMMENT Setting Initial Values of n and R
.   LET n = SIZE $samp_a
    LET n = SIZE samp_a
    LET r = 0.0
 

COMMENT Normalizing to Meet Probability Assumption (Values Sum to One)
.   LET sum_a = SUM $samp_a
    LET sum_a = SUM samp_a
.   LET sum_b = SUM $samp_b
    LET sum_b = SUM samp_b

.   LET $samp_a = $samp_a/sum_a
    LET samp_a = samp_a/sum_a
.   LET $samp_b = $samp_b/sum_b
    LET samp_b = samp_b/sum_b
    DELETE sum_a sum_b

COMMENT Looping through values of a and b
    ECHO OFF
    FEEDBACK OFF
    LOOP FOR I = 1 1 N
        .   Getting Iteration Values
        .   LET ai = $samp_a(I)
            LET ai = samp_a(I)
        .   LET bi = $samp_b(I)
            LET bi = samp_b(I)
        
        .   Evaluating sample_a with reference to bi
            IF ai > 0
                LET i_value = ai * LOG(ai/bi) - ai + bi
                LET r = r + i_value
                DELETE i_value
            ELSE 
                LET r = r + bi
            END OF IF
    END OF LOOP
    FEEDBACK ON
    ECHO ON