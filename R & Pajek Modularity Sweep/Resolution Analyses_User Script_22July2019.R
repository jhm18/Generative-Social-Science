#Jonathan H. Morgan
#Resolution Analysis Functions User Script
#22 July 2019

#Clear Out Console Script
cat("\014")

#Clearing Old Data
rm(list = ls())
gc()

#Setting Home Directory
setwd("/Users/jhmorgan/Desktop/Personal/GPM_Diss")
getwd()

#Setting Output directory for writing out files
DATA.DIR <- ("/Users/jhmorgan/Desktop/Personal/GPM_Diss")

#Setting Network Directory of Interest
setwd('./Time1_Language')
getwd()

#Pulling in Functions to Perform Analyses
source("/Applications/Pajek64/R_Pajek Functions_15July2019.R")
source('/Applications/Pajek64/Resolution Analyses_23July2019.R')

#NOTE: Both reolution analysis utilities assume that the Pajek macro (.mcr) that generates and save the partitions uses a canonnical 
#      partition label: name__resolution value_iteration number (e.g., Time1Structure__0.5_1.clu)
#      Please refer to the example .mcr fil that comes with this user script. These analyes examine resolution values from 0.5 to 1.8 in .5 intervals,
#      but they could support a different range of resolution values or a different interval.

#Also these functions assume that you are using the R Pajek functions to read in the relevant Pajek file.

############################################
#   BASIC RESOLUTION ANALYSIS: basic_res   #
############################################
      #The purpose of basic_res is to get a first look. The function runs nearly instantly, and provides a sense of the number of communtities 
      #generally associated wityh each resolution value.
      #Generally, we are looking plateau with the intuition that that this indicates a realtively stable set of community solutions.
      #The function reads the report generated and saved by the Pajek macro file.
      #Consequently, when we call the function, a report list is generated so the user can easily select the relevant report.

basic_res(Rep_Files[[1]])
#Note ggplot2 generates the warning because we are using a spline to smooth out line in the graph, resulting in the loss of duplicate x values

#Plot Object for Inspection
`Basic Resolution`

###################################################
#   MODULARITY AND STABILITY ANALYSES: mod_proc   #
###################################################
      #The purpose of mod_proc is to assess partition solution in terms of an optimality enveolope described by Wier et. al. 2017 and the relative
      #stabiilty of the solution in terms of mean and confidence interval generated by calculating the Adjusted Rand Score for each pair of communities
      #for each resolution value, 27 values with 10 pairwise comparisons at each value for the analyses described here.
      #The modularity optimality analyses allow us to immediately disqualify solutions following outside of the envelope, while the stibility analyse
      #provide futher insight in whether the solution is relabily identifying the same people to the same communities across runs.

#Arguments
  #mod_proc requires that the network file and the partitions of interest as inputs. 
  #The user need to read the patition file to ensure that the file lists only the vertex id and community solutions of interest

#On PCs it an be helpful to increase the memory limit for the this function
  #memory.limit()
  #memory.limit(size=3000)  Don't need to be crazy just a boost

#Reading in the partition files with read_clu
read_clu()

#Delete partitions associated with other networks in the directory (e.g., Time 1 Language)
rm(Partition_1, Partition_2, Partition_3)

#IMPORTANT: Assumes only id and cluster solutions
  #Thus, deleting the network size column and two weak component partitions

#Note: If the function is taking a long time to run, stop it and check that only
#the community solutions are in the input file.

#Time 1: Structure
clu <- as.data.frame(Partition_1[-c(1, 3:4)])

#Time 1: Language
clu <- as.data.frame(Partition_4[-c(1, 3)])

#Checking that I have the right network by checking that the number of vertices in my network match the number in my partition input file. 

#Time 1: Structure
read_net(Net_Files[[2]])

#Time 1: Language
read_net(Net_Files[[3]])

#RUNNING THE FUNCTION

#Time 1: Structure
mod_proc(Net_Files[[2]], clu)  #This takes some time depending on the size and density of the network being analyzed

#Time 1: Langauge
mod_proc(Net_Files[[3]], clu)

#Output fles
  #Modularity:  The full modularity statistics for all non-duplicate community solutions
  #Optimal Modularity: The modularity statistics for the community in each partition with the highest quality score
  #Aggregate ARI Statistics: The aggregate Adjusted Rand score for resolution value, generated from the n(n-1)/2 pairwise combinations
  #Convex Hull Optimality: Visualization of the Optimality Envelope and group size per resolution value
  #ARI Partition Consensus: Visualzation of the mean and confidence interval of the ARI stability analysis
  #Modularity Profile: A side-by-side panel plot of the two analyses used to help finalize a decision on which community partition to choose

#Datasets
Modularity
`Optimal Modularity`
`Aggregate ARI Statistics`

#Visualizations
`Convex Hull Optimality`
`ARI Partition Consensus`
`Modularity Profile`

#SAVING VISUALIZATIONS

#Time 1: Structure
ggsave(`Convex Hull Optimality`,file='Time 1_Structure Network_CHAMPS.eps', width = 20, height = 20, units = "cm", dpi=600)
ggsave(`ARI Partition Consensus`, file='Time 1_Structure Network_ARI Con.eps', width = 20, height = 20, units = "cm", dpi=600)

#Time 1: Language
ggsave(`Basic Resolution`,file='Time 1_Language Network_Basic Resolution.eps', width = 20, height = 20, units = "cm", dpi=600)
ggsave(`Convex Hull Optimality`,file='Time 1_Language Network_CHAMPS.svg', width = 20, height = 20, units = "cm", dpi=600)
ggsave(`ARI Partition Consensus`, file='Time 1_Language Network_ARI Con.svg', width = 20, height = 20, units = "cm", dpi=600)
ggsave(`Modularity Profile`, file='Time 1_Language Network_Modularity Profile.svg', width = 40, height = 25, units = "cm", dpi=600)
